import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import os
from google.colab import drive
import itertools
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D,
    BatchNormalization, Flatten,
    Dense, Dropout
)
from sklearn.metrics import confusion_matrix, classification_report


#  1. Montowanie Dysku Google i ustawienie ścieżki do danych
drive.mount('/content/drive')

# Ścieżka do folderu z danymi na Dysku Google
dataset_path = '/content/drive/MyDrive/dataset'

if os.path.exists(dataset_path):
    print("Folder znaleziony:", dataset_path)
else:
    print("Folder nie istnieje, sprawdź ścieżkę:", dataset_path)

#  2. Przygotowanie danych

# Generator danych dla treningu – z augmentacją
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Generator danych dla walidacji i testu – tylko reskalowanie
val_test_datagen = ImageDataGenerator(rescale=1./255)

# Używamy os.path.join do wygodnego łączenia ścieżek
train_data = train_datagen.flow_from_directory(
    os.path.join(dataset_path, 'train'),
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'  # Trzy klasy: brain_glioma, brain_menin, brain_tumor
)

val_data = val_test_datagen.flow_from_directory(
    os.path.join(dataset_path, 'validation'),
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

test_data = val_test_datagen.flow_from_directory(
    os.path.join(dataset_path, 'test'),
    target_size=(128, 128),
    batch_size=32,
    class_mode='categorical'
)

# Wyświetlenie przykładowych obrazów z danych treningowych
images, labels = next(train_data)

fig, axes = plt.subplots(1, 5, figsize=(15, 5))
for i in range(5):
    axes[i].imshow(images[i])
    axes[i].axis('off')
    # Jako że etykiety są one-hot encoded, pobieramy indeks klasy
    label_index = np.argmax(labels[i])
    axes[i].set_title(f'Label: {label_index}')
plt.show()

# 3. Definicja modelu CNN

def create_cnn_model():
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
        MaxPooling2D(2, 2),

        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Conv2D(128, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),

        Flatten(),
        Dense(128, activation='relu'),
        Dropout(0.5),
        Dense(3, activation='softmax')  # 3 klasy
    ])

    model.compile(optimizer=Adam(learning_rate=0.001),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])
    return model

model = create_cnn_model()
model.summary()

#4. Trening modelu

history = model.fit(train_data, validation_data=val_data, epochs=10)

# 5. Wizualizacja wyników
# Wykres dokładności treningowej i walidacyjnej
plt.figure(figsize=(10, 5))
epochs = range(1, len(history.history['accuracy']) + 1)  # Numeracja epok od 1 do 10
plt.plot(epochs, history.history['accuracy'], label='Train Accuracy')
plt.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoki')
plt.ylabel('Dokładność')
plt.title('Dokładność modelu')
plt.xticks(epochs)  # Ustawienie xticks na wszystkie epoki
plt.legend()
plt.show()

# Przykładowe symulowane dane do wizualizacji histogramów
accuracy_scores = np.random.normal(0.85, 0.05, 100)        # Skuteczność modelu
tumor_parameters = np.random.rand(100, 4) * 100              # Parametry guza: intensywność, wielkość, położenie, rodzaj
operability_factors = np.random.rand(100, 3) * 100           # Czynniki operacyjności: rozmiar, lokalizacja, stopień zaawansowania

# Histogram skuteczności modelu
plt.figure(figsize=(8, 6))
sns.histplot(accuracy_scores, bins=15, kde=True)
plt.xlabel("Skuteczność modelu")
plt.ylabel("Liczba przypadków")
plt.title("Histogram skuteczności wykrywania raka mózgu")
plt.show()

# Histogramy parametrów guza
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
titles = ["Intensywność zmian", "Wielkość nowotworu", "Położenie guza", "Rodzaj nowotworu","Stopień zaawansowania"]
for i, ax in enumerate(axes.flatten()):
    sns.histplot(tumor_parameters[:, i], bins=15, kde=True, ax=ax)
    ax.set_title(titles[i])
plt.tight_layout()
plt.show()

# 2. Przygotowanie generatorów
# 2a. Bez augmentacji
basic_datagen = ImageDataGenerator(rescale=1./255)
# 2b. Z augmentacją
aug_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

def create_generators(datagen):
    """Zwraca train, val, test generatory."""
    train = datagen.flow_from_directory(
        os.path.join(dataset_path, 'train'),
        target_size=(128,128), batch_size=32, class_mode='categorical'
    )
    val = basic_datagen.flow_from_directory(
        os.path.join(dataset_path, 'validation'),
        target_size=(128,128), batch_size=32, class_mode='categorical'
    )
    test = basic_datagen.flow_from_directory(
        os.path.join(dataset_path, 'test'),
        target_size=(128,128), batch_size=32, class_mode='categorical', shuffle=False
    )
    return train, val, test

# 3. Funkcja budująca model
def build_model(variant='baseline', lr=1e-3):
    layers = []
    # 3x Conv→Pool
    for filters in [32, 64, 128]:
        layers.append(Conv2D(filters, (3,3), activation='relu', padding='same'))
        if variant == 'batchnorm':
            layers.append(BatchNormalization())
        layers.append(MaxPooling2D((2,2)))
    layers.append(Flatten())
    layers.append(Dense(128, activation='relu'))
    if variant in ['dropout', 'batchnorm+dropout']:
        layers.append(Dropout(0.5))
    layers.append(Dense(3, activation='softmax'))

    model = Sequential(layers)
    model.compile(
        optimizer=Adam(learning_rate=lr),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model

# 4. Definicja eksperymentów
experiments = [
    # (nazwa, datagen, model_variant, learning_rate)
    ("A_basic_aug",   aug_datagen,        'baseline',         1e-3),
    ("B_no_aug",      basic_datagen,      'baseline',         1e-3),
    ("C_dropout",     aug_datagen,        'dropout',          1e-3),
    ("D_batchnorm",   aug_datagen,        'batchnorm',        1e-3),
    ("E_lr_low",      aug_datagen,        'baseline',         1e-4),
]

results = {}

# 5. Pętla trenowania
for name, datagen, variant, lr in experiments:
    print(f"\n--- Startujemy eksperyment: {name} ---")
    train_gen, val_gen, test_gen = create_generators(datagen)
    model = build_model(variant, lr)
    hist = model.fit(
        train_gen,
        validation_data=val_gen,
        epochs=10,
        verbose=1
    )
    # Zapisujemy historię i generator testowy
    results[name] = {
        'history': hist.history,
        'model': model,
        'test_gen': test_gen
    }

# 6. Porównawcze wykresy accuracy & val_accuracy
plt.figure(figsize=(12, 6))
for name, res in results.items():
    epochs = range(1, len(res['history']['accuracy']) + 1)
    plt.plot(epochs, res['history']['val_accuracy'], label=f"{name}")
plt.title("Porównanie Validation Accuracy")
plt.xlabel("Epoka")
plt.ylabel("Val Accuracy")
plt.legend()
plt.show()

# 7. Wybieramy najlepszy model na podstawie max val_accuracy
best_name, best_info = max(
    results.items(),
    key=lambda kv: max(kv[1]['history']['val_accuracy'])
)
print(f"\nNajlepszy wariant: {best_name}")

# 8. Ewaluacja na zbiorze testowym + macierz pomyłek
best_model = best_info['model']
test_gen = best_info['test_gen']
test_steps = test_gen.samples // test_gen.batch_size + 1
y_pred_probs = best_model.predict(test_gen, steps=test_steps)
y_pred = np.argmax(y_pred_probs, axis=1)
y_true = test_gen.classes
labels = list(test_gen.class_indices.keys())


# 8a. Macierz pomyłek
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=labels, yticklabels=labels)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title(f"Confusion Matrix: {best_name}")
plt.show()

# 8b. Raport klasyfikacji
print("\nClassification Report:\n")
print(classification_report(y_true, y_pred, target_names=labels))

